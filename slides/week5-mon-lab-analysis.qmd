---
title: "Lab: Analisi Contenuti con IA"
subtitle: "IA Generativa e Media ‚Äî Settimana 5"
author: "Fabio Giglietto"
institute: "DISCUI ¬∑ Universit√† degli Studi di Urbino Carlo Bo"
date: "23 Marzo 2026"
date-format: "D MMMM YYYY"
format:
  revealjs:
    theme: [default, ../_extensions/uniurb/discui.scss]
    logo: ../assets/logo-uniurb-white.svg
    footer: "IA Generativa e Media ¬∑ A.A. 2025/2026"
    slide-number: c/t
    transition: fade
    width: 1920
    height: 1080
    margin: 0.08
    center: false
    hash: true
    controls: true
    progress: true
execute:
  echo: true
  warning: false
  message: false
  fig-width: 10
  fig-height: 6
  fig-dpi: 150
knitr:
  opts_chunk:
    dev: "ragg_png"
lang: it
bibliography: ../references.bib
csl: ../apa.csl
---

## Roadmap del lab

1. **Ricapitolazione** ‚Äî stato dei dataset raccolti
2. **Costruire il codebook** ‚Äî categorie di analisi per i commenti
3. **Prompt engineering per la codifica** ‚Äî istruzioni sistematiche a Gemini
4. **Classificazione automatizzata** ‚Äî analizzare i commenti con Gemini
5. **Gestione del contesto lungo** ‚Äî caricare dataset ampi
6. **Lavoro pratico** ‚Äî codifica dei commenti per gruppi

::: {.notes}
Struttura del lab. Oggi passiamo dalla raccolta all'analisi. La sessione di mercoled√¨ scorso ha prodotto i dataset; oggi applichiamo la prima fase della pipeline LLMs-in-the-loop per classificare i commenti. L'obiettivo √® che ogni gruppo esca con una prima classificazione automatizzata dei propri commenti, pronta per la validazione umana di domani.
:::

## Stato dei Dataset {background-color="#C5612E"}

::: {.notes}
Sezione 1: verifica rapida dei dati raccolti mercoled√¨. Momento per risolvere problemi residui prima di procedere con l'analisi.
:::

## Verifica dei dati raccolti

::: {.columns}
::: {.column width="50%"}
### Requisiti minimi

- **30+ post** con immagini AI-generated
- **Commenti** scaricati per ogni post
- **Foglio di calcolo** condiviso e accessibile
- **Query documentate** con parametri
:::

::: {.column width="50%"}
### Controllo qualit√†

- Le immagini sono effettivamente AI?
- I commenti sono leggibili e completi?
- I metadata (date, metriche) sono presenti?
- Ci sono **duplicati** da rimuovere?
:::
:::

::: {.callout-warning}
## Attenzione
Se il dataset ha meno di 30 post, dedicate i primi 20 minuti a integrare la raccolta. L'analisi richiede un volume minimo di dati.
:::

::: {.notes}
Verifica rapida: ogni gruppo mostra il proprio foglio di calcolo. 5 minuti per verificare che tutti siano pronti. I gruppi con dataset incompleti dedicano i primi 20 minuti a integrare. Problemi comuni emersi mercoled√¨: commenti non completamente scaricati, duplicati, immagini ambigue. Per le immagini ambigue, suggerire di tenerle ma annotarle come "incerto" nella colonna tipo_immagine. Meglio avere dati in pi√π da escludere dopo che dati insufficienti.
:::

## Costruire il Codebook {background-color="#C5612E"}

::: {.notes}
Sezione 2: definizione delle categorie di analisi. Il codebook √® il documento fondamentale per la classificazione sistematica.
:::

## Cos'√® un codebook

::: {.highlight-box}
**Codebook:** documento che definisce le **categorie di analisi**, le **regole di classificazione** e gli **esempi** per ogni categoria. Garantisce che tutti i codificatori (umani e IA) applichino gli stessi criteri [@marino2024].
:::

Elementi essenziali:

- **Nome della variabile** ‚Äî cosa si classifica
- **Categorie** ‚Äî le opzioni possibili (mutuamente esclusive)
- **Definizione operativa** ‚Äî cosa significa ogni categoria
- **Esempi** ‚Äî commenti concreti per ogni categoria
- **Regole per i casi ambigui** ‚Äî come decidere nei casi limite

::: {.notes}
Il codebook √® lo strumento centrale dell'analisi del contenuto. Nella metodologia LLMs-in-the-loop di Marino & Giglietto (2024), il codebook serve a due scopi: (1) guidare la classificazione umana e (2) fornire le istruzioni per il prompt che sar√† dato al LLM. La qualit√† del codebook determina la qualit√† dell'analisi. Un codebook ambiguo produce classificazioni incoerenti sia negli umani che nell'IA. Enfatizzare che le categorie devono essere mutuamente esclusive e collettivamente esaustive.
:::

## Categorie per i commenti *AI slop*

| Categoria | Definizione | Esempio |
|-----------|------------|---------|
| **Riconoscimento IA** | L'utente identifica l'immagine come generata dall'IA | "Si vede che √® fatta con l'intelligenza artificiale" |
| **Reazione emotiva** | Risposta emotiva senza riferimento all'IA | "Che bello, mi commuove!" |
| **Critica** | Commento negativo verso il contenuto o la pagina | "Smettetela di postare questa spazzatura" |
| **Engagement genuino** | Interazione con il contenuto come se fosse autentico | "Dove si trova questo posto?" |
| **Altro** | Commenti non classificabili nelle categorie precedenti | Emoji senza testo, tag di amici |

::: {.notes}
Proposta di codebook di base per l'analisi dei commenti. I gruppi possono adattare queste categorie alla loro domanda di ricerca specifica: ad esempio, un gruppo che studia il riconoscimento dell'IA potrebbe aggiungere sottocategorie ("riconoscimento esplicito", "sospetto", "richiesta di conferma"). Un gruppo che studia le emozioni potrebbe distinguere tra emozioni positive e negative. Ogni gruppo dovr√† definire il proprio codebook specifico entro la fine della sessione. Le categorie proposte qui sono un punto di partenza, non un vincolo.
:::

## Esercizio: definire il codebook di gruppo

::: {.orange-box}
### Attivit√† (15 minuti)
1. Partendo dalle categorie di base, **adattate il codebook** alla vostra domanda di ricerca
2. Aggiungete **almeno 3 esempi concreti** dal vostro dataset per ogni categoria
3. Definite le **regole per i casi ambigui** (es. un commento che contiene sia riconoscimento IA che emozione)
4. Scrivete il codebook in un **documento Google Docs** condiviso
:::

::: {.callout-tip}
## Suggerimento
Un buon test: prendete 5 commenti e chiedete a due membri del gruppo di classificarli indipendentemente. Se non concordano, il codebook va raffinato.
:::

::: {.notes}
Esercizio pratico fondamentale. Dare 15 minuti per il lavoro in gruppo. Il test di concordanza √® molto importante: se due umani non concordano sulla classificazione di un commento, non possiamo aspettarci che lo faccia l'IA. Il codebook deve essere sufficientemente chiaro da ridurre al minimo l'ambiguit√†. Passare tra i gruppi per verificare che le definizioni operative siano precise e che gli esempi siano effettivamente rappresentativi. Il documento del codebook servira' anche come base per la sezione Metodo del paper.
:::

## Prompt Engineering per la Codifica {background-color="#C5612E"}

::: {.notes}
Sezione 3: come tradurre il codebook in un prompt efficace per Gemini. Questa √® la fase chiave del processo LLMs-in-the-loop.
:::

## Dal codebook al prompt

La qualit√† della classificazione automatizzata dipende dalla qualit√† del prompt. Seguiamo la struttura di @cosenza2025:

::: {.columns}
::: {.column width="50%"}
### Struttura del prompt

1. **Ruolo:** analista di contenuti
2. **Obiettivo:** classificare commenti
3. **Istruzioni:** il codebook completo
4. **Contesto:** informazioni sull'AI slop
5. **Output:** formato tabellare strutturato
:::

::: {.column width="50%"}
### Principi chiave

- **Esplicitare tutto:** non lasciare spazi di libert√†
- **Dare esempi:** few-shot per ogni categoria
- **Definire il formato:** tabella con colonne fisse
- **Gestire l'incertezza:** categoria "incerto" ammessa
:::
:::

::: {.notes}
Tradurre il codebook in un prompt √® l'operazione chiave della metodologia LLMs-in-the-loop. Cosenza (2025) nella regola "Dirigi" sottolinea che prompt vaghi producono risultati generici. Qui applichiamo lo stesso principio alla ricerca: pi√π il prompt √® preciso e strutturato, pi√π la classificazione sar√† coerente. I principi chiave: (1) includere il codebook completo nel prompt, (2) fornire almeno 2-3 esempi per categoria (few-shot learning), (3) definire esattamente il formato dell'output per facilitare il data entry, (4) prevedere l'incertezza con una categoria dedicata piuttosto che forzare classificazioni dubbie.
:::

## Esempio di prompt per la classificazione

::: {.highlight-box}
*"Agisci come un analista di contenuti specializzato in social media. Il tuo compito √® classificare i commenti degli utenti a post contenenti immagini generate dall'IA (AI slop) su Facebook.*

*Classifica ogni commento in UNA delle seguenti categorie:*

*1. RICONOSCIMENTO_IA ‚Äî l'utente identifica l'immagine come generata dall'IA*
*2. REAZIONE_EMOTIVA ‚Äî risposta emotiva senza menzionare l'IA*
*3. CRITICA ‚Äî commento negativo verso il contenuto*
*4. ENGAGEMENT_GENUINO ‚Äî interazione come se il contenuto fosse autentico*
*5. ALTRO ‚Äî non classificabile*

*Per ogni commento, fornisci: ID, CATEGORIA, LIVELLO_CERTEZZA (alto/medio/basso).*

*Formato output: tabella CSV con colonne: id, categoria, certezza, motivazione_breve"*
:::

::: {.notes}
Prompt di esempio che i gruppi possono adattare. Notare gli elementi: ruolo (analista di contenuti), contesto (AI slop su Facebook), istruzioni precise (le categorie con definizioni), formato output (tabella CSV con colonne specifiche). Il livello di certezza √® importante: permette di identificare i casi su cui la validazione umana dovr√† concentrarsi. La motivazione breve aiuta a capire il ragionamento dell'IA e a verificarne la coerenza. I gruppi dovranno sostituire le categorie con quelle del loro codebook specifico.
:::

## Strategie per prompt coerenti

::: {.columns}
::: {.column width="50%"}
### Il problema della coerenza

- L'IA pu√≤ classificare lo **stesso commento** in modo diverso in sessioni diverse
- La **lunghezza del prompt** influisce sulla qualit√†
- Il **contesto accumulato** pu√≤ creare drift
:::

::: {.column width="50%"}
### Le soluzioni

- **Prompt fisso:** usare sempre lo stesso testo base
- **Batch piccoli:** classificare 20-30 commenti alla volta
- **Nuova sessione:** aprire una chat pulita per ogni batch
- **Temperatura bassa:** se disponibile, ridurre la variabilit√†
:::
:::

::: {.notes}
Problema cruciale: la coerenza della classificazione. A differenza di un codificatore umano che migliora con la pratica, un LLM pu√≤ produrre classificazioni leggermente diverse per lo stesso input in momenti diversi. Strategie pratiche: (1) usare sempre lo stesso prompt, copiandolo da un documento sorgente; (2) dividere il dataset in batch di 20-30 commenti; (3) aprire una nuova chat per ogni batch per evitare l'effetto del contesto accumulato; (4) annotare il batch e la sessione per ogni classificazione. Queste accortezze derivano dall'esperienza pratica con la metodologia LLMs-in-the-loop.
:::

## Gestione del Contesto Lungo {background-color="#C5612E"}

::: {.notes}
Sezione 4: come sfruttare la finestra di contesto di 1 milione di token di Gemini per analizzare dataset ampi.
:::

## Il vantaggio del contesto lungo in Gemini

::: {.highlight-box}
**Gemini** offre una finestra di contesto fino a **1 milione di token** ‚Äî equivalente a circa **700.000 parole** o centinaia di pagine di testo.
:::

Cosa significa per il progetto:

- Caricare l'**intero dataset** di commenti in una singola sessione
- Fornire il **codebook completo** con molti esempi
- Mantenere il **contesto** durante la classificazione
- Chiedere **statistiche aggregate** dopo la classificazione

::: {.callout-warning}
## Attenzione
Un contesto pi√π lungo non garantisce risultati migliori. Testate con un **campione ridotto** prima di classificare l'intero dataset.
:::

::: {.notes}
La finestra di contesto di Gemini √® un vantaggio significativo per l'analisi del contenuto. Con 1 milione di token, possiamo caricare centinaia o migliaia di commenti in una singola sessione, insieme al codebook e agli esempi. Tuttavia, la qualit√† della classificazione non scala linearmente con la quantit√† di dati: contesti molto lunghi possono portare a un degradamento dell'attenzione del modello sulle istruzioni. La strategia consigliata: iniziare con un campione di 20-30 commenti, verificare la qualit√†, e poi scalare progressivamente.
:::

## Workflow pratico con Gemini

**Passo 1 ‚Äî Preparare il file:**

- Esportare i commenti in un **file di testo** o **CSV**
- Numerare ogni commento con un **ID univoco**

**Passo 2 ‚Äî Costruire il prompt:**

- Inserire il **codebook** con definizioni e esempi
- Specificare il **formato di output** (CSV/tabella)

**Passo 3 ‚Äî Caricare e classificare:**

- Allegare il file a Gemini e incollare il prompt
- Verificare i primi **10 risultati** per coerenza
- Se soddisfacenti, procedere con il **dataset completo**

**Passo 4 ‚Äî Estrarre i risultati:**

- Copiare la tabella di output nel **foglio Google Sheets**
- Verificare che tutti i commenti siano stati classificati

::: {.notes}
Workflow operativo passo per passo. Passo 1: la preparazione del file √® cruciale ‚Äî ogni commento deve avere un ID univoco che corrisponda a quello nel foglio di calcolo. Passo 2: il prompt deve contenere il codebook completo; non fare affidamento sulla memoria della sessione precedente. Passo 3: i primi 10 risultati servono come test di qualit√† ‚Äî se la classificazione non √® soddisfacente, bisogna rivedere il prompt o il codebook prima di procedere. Passo 4: l'output va nella colonna "classificazione_ai" del foglio Commenti. Se Gemini non riesce a classificare tutti i commenti in un unico batch, dividere in batch da 50-100.
:::

## Lavoro Pratico {background-color="#C5612E"}

::: {.notes}
Sezione 5: lavoro pratico di classificazione. I gruppi applicano quanto discusso.
:::

## Istruzioni per il lavoro di gruppo

::: {.orange-box}
### Obiettivo del lab (60 minuti)
Ogni gruppo: (1) finalizza il proprio **codebook**, (2) costruisce il **prompt** di classificazione, (3) classifica **almeno 50 commenti** con Gemini, (4) annota i risultati nel foglio condiviso.
:::

**Fasi operative:**

1. **0-15 min:** finalizzare il codebook (se non gi√† fatto)
2. **15-25 min:** scrivere e testare il prompt con 10 commenti
3. **25-55 min:** classificare i restanti commenti
4. **55-60 min:** verificare i risultati e annotare problemi

::: {.notes}
Fase pratica del lab. I gruppi lavorano autonomamente. Il docente passa tra i gruppi per: (1) verificare la qualit√† dei codebook, (2) suggerire miglioramenti ai prompt, (3) aiutare con problemi tecnici di Gemini. Problemi comuni: commenti troppo corti per essere classificati (emoji, singole parole), commenti in lingue diverse dall'italiano, commenti spam. Suggerire di classificare questi casi come "ALTRO" e annotarli. L'obiettivo di 50 commenti √® un minimo; gruppi con dataset pi√π grandi possono classificare di pi√π.
:::

## Checklist di fine lab

Prima di uscire, ogni gruppo verifica:

- [ ] **Codebook** finalizzato e documentato
- [ ] **Prompt** testato e salvato in un documento condiviso
- [ ] **Almeno 50 commenti** classificati da Gemini
- [ ] **Risultati** inseriti nella colonna "classificazione_ai"
- [ ] **Problemi** annotati (commenti difficili, ambiguit√†)

::: {.callout-note}
## Per domani
Domani affronteremo la **validazione umana** delle classificazioni IA. Ogni membro del gruppo dovr√† classificare manualmente un campione di commenti per calcolare l'**intercoder reliability**.
:::

::: {.notes}
Checklist di verifica. Enfatizzare che il prompt va salvato in un documento condiviso: servir√† sia per la sezione Metodo del paper sia per eventuali iterazioni. I commenti classificati come "incerti" dall'IA saranno il primo target della validazione umana di domani. I problemi annotati alimenteranno la discussione sulla validazione. Transizione: domani passiamo dalla classificazione automatizzata alla verifica umana ‚Äî il cuore della metodologia LLMs-in-the-loop.
:::

## Grazie! {background-color="#C5612E"}

**Prossima lezione:** Validazione ‚Äî Umano vs Macchina (24 Marzo 2026)

üìß fabio.giglietto@uniurb.it

üåê blended.uniurb.it

::: {.notes}
Chiusura. Ricordare: (1) verificare che i risultati della classificazione IA siano nel foglio condiviso, (2) domani ogni membro del gruppo dovr√† classificare manualmente un campione di commenti, (3) portare il codebook stampato o su tablet per la codifica manuale. Domani √® la sessione chiave della metodologia: confronteremo le classificazioni IA con quelle umane.
:::

## Riferimenti
