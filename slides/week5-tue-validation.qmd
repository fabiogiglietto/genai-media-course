---
title: "Validazione: Umano vs Macchina"
subtitle: "IA Generativa e Media ‚Äî Settimana 5"
author: "Fabio Giglietto"
institute: "DISCUI ¬∑ Universit√† degli Studi di Urbino Carlo Bo"
date: "24 Marzo 2026"
date-format: "D MMMM YYYY"
format:
  revealjs:
    theme: [default, ../_extensions/uniurb/discui.scss]
    logo: ../assets/logo-nh-uniurb.svg
    footer: "IA Generativa e Media ¬∑ A.A. 2025/2026"
    slide-number: c/t
    transition: fade
    width: 1920
    height: 1080
    margin: 0.08
    center: false
    hash: true
    controls: true
    progress: true
execute:
  echo: true
  warning: false
  message: false
  fig-width: 10
  fig-height: 6
  fig-dpi: 150
knitr:
  opts_chunk:
    dev: "ragg_png"
lang: it
bibliography: ../references.bib
csl: ../apa.csl
---

## Roadmap della sessione

1. **Perch√© validare** ‚Äî il ruolo della verifica umana
2. **La metodologia LLMs-in-the-loop** ‚Äî pipeline e principi
3. **Progettare il protocollo di validazione** ‚Äî campionamento e codifica
4. **Misurare l'accordo** ‚Äî Cohen's kappa e Krippendorff's alpha
5. **Esercizio pratico** ‚Äî validare un campione di commenti
6. **Iterazione e raffinamento** ‚Äî migliorare la pipeline

::: {.notes}
Struttura della sessione. Oggi √® il giorno chiave per la qualit√† metodologica del progetto. Ieri i gruppi hanno classificato i commenti con Gemini; oggi confrontiamo quelle classificazioni con il giudizio umano. L'obiettivo √® duplice: (1) verificare quanto l'IA √® affidabile e (2) apprendere la metodologia di validazione che sar√† documentata nel paper. Questa sessione alterna teoria (30%) e pratica (70%).
:::

## Perch√© Validare {background-color="#C5612E"}

::: {.notes}
Sezione 1: motivazione della validazione. Perch√© non basta la classificazione automatizzata.
:::

## L'IA non √® un oracolo

::: {.highlight-box}
**Principio fondamentale:** come ci ricorda @cosenza2025, l'IA ragiona per **probabilit√†**, non per verit√†. Ogni classificazione automatizzata √® una **bozza** che richiede verifica.
:::

Perch√© la classificazione dell'IA pu√≤ essere inaffidabile:

- **Sensibilit√† al prompt:** piccole variazioni producono risultati diversi
- **Bias del modello:** tendenza a sovra-rappresentare alcune categorie
- **Ambiguit√† linguistica:** ironia, sarcasmo, dialetto sono difficili da interpretare
- **Mancanza di contesto:** l'IA non conosce il contesto culturale specifico

::: {.notes}
Collegamento con la regola 4 di Cosenza (2025): "Valuta". L'IA non √® stata progettata per dire la verit√†, ma per generare l'output pi√π probabile. Nel contesto della classificazione dei commenti, questo significa che l'IA pu√≤ classificare correttamente i casi chiari ma sbagliare sistematicamente sui casi ambigui. L'ironia √® particolarmente problematica: un commento come "bellissimo, proprio come una foto vera!" potrebbe essere sarcasmo (riconoscimento IA) o genuino (engagement). Il contesto culturale italiano aggiunge complessit√†: espressioni dialettali, riferimenti locali, humor specifico. Per questo la validazione umana non √® un optional ma un requisito metodologico.
:::

## Il paradosso della fiducia nell'IA

::: {.columns}
::: {.column width="50%"}
### Il rischio

Ferrara (2026) descrive un **paradosso**: pi√π l'IA sembra affidabile, pi√π rischiamo di fidarci ciecamente dei suoi output [@ferrara2026].

Nella ricerca, questo si traduce in:

- Accettare classificazioni senza verifica
- Non documentare gli errori dell'IA
- Presentare risultati non validati
:::

::: {.column width="50%"}
### La soluzione

La **validazione sistematica** protegge da questo rischio:

- Codifica umana indipendente
- Confronto quantitativo IA-umano
- Documentazione trasparente
- Iterazione basata sugli errori
:::
:::

::: {.notes}
Il collegamento con Ferrara (2026) √® importante: il Generative AI Paradox si applica anche alla ricerca. Come i cittadini possono cadere nella "credulity" (credere a contenuti sintetici convincenti), i ricercatori possono cadere nell'accettare acriticamente classificazioni IA apparentemente plausibili. La validazione sistematica √® l'antidoto: trattare l'IA come un codificatore le cui classificazioni devono essere verificate, esattamente come faremmo con un codificatore umano alle prime armi. Questo approccio √® al centro della metodologia LLMs-in-the-loop.
:::

## La Metodologia LLMs-in-the-loop {background-color="#C5612E"}

::: {.notes}
Sezione 2: approfondimento della metodologia. Qui espandiamo quanto introdotto nel lancio del progetto.
:::

## La pipeline LLMs-in-the-loop

::: {.orange-box}
**Definizione**

La metodologia *LLMs-in-the-loop* integra l'analisi automatizzata dei LLM con la validazione sistematica umana, trattando l'IA come un "codificatore" le cui classificazioni vengono verificate contro il giudizio umano [@marino2024].
:::

La pipeline prevede un **ciclo iterativo:**

1. Definizione del codebook
2. Prompting sistematico al LLM
3. Classificazione automatizzata
4. **Validazione umana** (focus di oggi)
5. Calcolo dell'affidabilit√† inter-codificatore
6. Iterazione e raffinamento

::: {.notes}
Ripresa pi√π approfondita della metodologia LLMs-in-the-loop di Marino & Giglietto (2024). Il punto chiave √® il ciclo iterativo: non si tratta di far classificare all'IA e poi verificare una volta. Si tratta di un processo in cui la validazione umana alimenta il raffinamento del prompt e del codebook, migliorando progressivamente la qualit√† della classificazione. Oggi ci concentriamo sulle fasi 4 e 5; nella parte finale della sessione affronteremo la fase 6. Il seminario di Bruna Paroni nella settimana 3 ha illustrato questa metodologia con un caso studio brasiliano.
:::

## L'IA come "codificatore"

Nella ricerca tradizionale sull'analisi del contenuto, si usano **codificatori umani** multipli per garantire affidabilit√†.

Con la pipeline LLMs-in-the-loop, l'IA diventa un **codificatore aggiuntivo**:

| Aspetto | Codificatore umano | Codificatore IA |
|---------|-------------------|-----------------|
| **Scala** | Centinaia di unit√† | Migliaia di unit√† |
| **Coerenza** | Fatica, distrazione | Dipende dal prompt |
| **Contesto** | Comprensione profonda | Comprensione superficiale |
| **Costo** | Alto (tempo, risorse) | Basso (computazionale) |
| **Verifica** | Intercoder reliability | IA vs. umano reliability |

::: {.notes}
Tabella comparativa che illustra i punti di forza e debolezza di codificatori umani e IA. L'IA eccelle nella scala (pu√≤ classificare migliaia di commenti in pochi minuti) e nel costo (quasi nullo). L'umano eccelle nella comprensione del contesto e nella capacit√† di cogliere sfumature. L'approccio LLMs-in-the-loop sfrutta entrambi: l'IA per la scala, l'umano per la qualit√† e la validazione. La metrica di affidabilit√† standard (intercoder reliability) viene applicata al confronto IA-umano esattamente come si applicherebbe al confronto tra due codificatori umani.
:::

## Progettare il Protocollo di Validazione {background-color="#C5612E"}

::: {.notes}
Sezione 3: aspetti pratici del protocollo di validazione. Come selezionare il campione e organizzare la codifica umana.
:::

## Selezionare il campione

::: {.highlight-box}
**Regola pratica:** validare almeno il **20-30%** del dataset totale, con un minimo di **50 unit√†** per l'analisi di affidabilit√†.
:::

Strategie di campionamento:

- **Campione casuale:** selezione randomizzata dal dataset completo
- **Campione stratificato:** includere commenti da tutte le categorie IA
- **Campione mirato:** includere i casi classificati come "incerti" dall'IA

::: {.callout-tip}
## Suggerimento
Combinate le strategie: un campione casuale (per la rappresentativit√†) + tutti i casi "incerti" dell'IA (per capire dove l'IA fatica di pi√π).
:::

::: {.notes}
Il campionamento √® cruciale per la validit√† della validazione. Il 20-30% √® una regola pratica consolidata nell'analisi del contenuto. Con dataset di 200-300 commenti (tipico per i gruppi), questo significa 50-80 commenti da classificare manualmente. Il campione stratificato garantisce che tutte le categorie siano rappresentate ‚Äî importante perch√© alcune categorie (es. "riconoscimento IA") potrebbero essere rare. I casi "incerti" sono particolarmente informativi: mostrano dove il codebook √® ambiguo e dove il prompt va migliorato.
:::

## Organizzare la codifica umana

| Fase | Azioni |
|------|--------|
| **Preparazione** | Estrarre campione in foglio separato, **rimuovere classificazione IA** (codifica cieca) |
| **Codifica** | Ogni codificatore classifica **indipendentemente** con lo stesso codebook |
| **Confronto** | Riunire classificazioni, confrontare con IA, calcolare metriche di **accordo** |

::: {.highlight-box}
**Cruciale:** i codificatori umani non devono vedere la classificazione IA per evitare il **bias di ancoraggio**.
:::

::: {.notes}
Il punto chiave √® la codifica cieca: i codificatori umani non devono vedere la classificazione dell'IA per evitare il bias di ancoraggio (tendenza a conformarsi alla classificazione gi√† presente). Idealmente, almeno 2 membri del gruppo codificano indipendentemente lo stesso campione: questo permette di calcolare sia l'accordo umano-umano (baseline) che l'accordo IA-umano. Se il gruppo ha 5 membri, suggerire 2 codificatori sul campione completo e gli altri 3 su sottoinsiemi. I casi difficili e le motivazioni alimentano la fase di iterazione.
:::

## Misurare l'Accordo {background-color="#C5612E"}

::: {.notes}
Sezione 4: le metriche statistiche per misurare l'accordo tra codificatori. Concetti tecnici necessari per il paper.
:::

## Perch√© non basta la percentuale di accordo

::: {.columns}
::: {.column width="50%"}
### Il problema

Due codificatori possono concordare **per caso**.

Se ci sono 2 categorie equiprobabili, il 50% di accordo √® atteso anche con classificazioni casuali.

La **percentuale di accordo grezzo** non tiene conto del caso.
:::

::: {.column width="50%"}
### La soluzione

Le metriche corrette sottraggono l'**accordo atteso per caso**:

$$\kappa = \frac{P_o - P_e}{1 - P_e}$$

Dove:

- $P_o$ = accordo osservato
- $P_e$ = accordo atteso per caso
:::
:::

::: {.notes}
Concetto statistico fondamentale per la validazione. La percentuale di accordo grezzo (quante volte i codificatori concordano sul totale) √® una metrica ingannevole perch√© non considera l'accordo casuale. Se abbiamo 5 categorie, l'accordo casuale atteso √® circa il 20%. Un accordo del 60% sembra buono ma dopo la correzione potrebbe essere modesto. Le metriche kappa e alpha correggono questo problema sottraendo l'accordo atteso per caso dal denominatore.
:::

## Cohen's kappa e Krippendorff's alpha

| Metrica | Uso | Caratteristiche |
|---------|-----|-----------------|
| **Cohen's kappa** ($\kappa$) | 2 codificatori | Semplice, ampiamente usato |
| **Krippendorff's alpha** ($\alpha$) | 2+ codificatori | Flessibile, gestisce dati mancanti |

::: {.highlight-box}
**Scale interpretative standard:**

| Valore | Interpretazione |
|--------|----------------|
| < 0.20 | Accordo scarso |
| 0.21 - 0.40 | Accordo discreto |
| 0.41 - 0.60 | Accordo moderato |
| 0.61 - 0.80 | Accordo buono |
| 0.81 - 1.00 | Accordo eccellente |
:::

::: {.notes}
Le due metriche principali per la validazione. Cohen's kappa √® la pi√π usata quando si confrontano 2 codificatori (nel nostro caso, IA vs. umano). Krippendorff's alpha √® pi√π flessibile: funziona con pi√π di 2 codificatori e gestisce i dati mancanti. Per il progetto, il kappa di Cohen √® sufficiente se si confronta 1 codificatore umano con l'IA; alpha di Krippendorff se si confrontano 2 codificatori umani + l'IA. L'obiettivo minimo per la ricerca √® un kappa/alpha di 0.60 (accordo buono). Valori inferiori indicano che il codebook o il prompt vanno rivisti. Nella sezione Metodo del paper, bisogna riportare la metrica usata, il valore ottenuto e l'interpretazione.
:::

## Calcolare il kappa: la matrice di confusione

Esempio con 3 categorie e 50 commenti:

|  | **Umano: Riconosc.** | **Umano: Emotivo** | **Umano: Critico** | **Totale IA** |
|--|:---:|:---:|:---:|:---:|
| **IA: Riconosc.** | **12** | 2 | 1 | 15 |
| **IA: Emotivo** | 3 | **18** | 2 | 23 |
| **IA: Critico** | 0 | 1 | **11** | 12 |
| **Totale umano** | 15 | 21 | 14 | **50** |

$P_o = (12+18+11)/50 = 0.82$ --- Calcolo manuale o con Gemini [@cosenza2025].

::: {.notes}
Esempio concreto di matrice di confusione. I valori in grassetto sulla diagonale sono i casi di accordo. I valori fuori diagonale sono i disaccordi. L'accordo osservato √® 0.82 (82%). L'accordo atteso per caso si calcola dai totali marginali. Due approcci per il calcolo: (1) manuale con foglio di calcolo ‚Äî creare la matrice, calcolare Po e Pe, applicare la formula; (2) con Gemini ‚Äî caricare le due colonne e chiedere il calcolo. Come suggerisce Cosenza (2025), usate entrambi per verificare. La matrice rivela i pattern di errore: l'IA confonde "Riconoscimento" con "Emotivo" 3 volte, guidando il raffinamento del prompt.
:::

## Esercizio Pratico {background-color="#C5612E"}

::: {.notes}
Sezione 5: esercizio di validazione. La parte centrale della sessione.
:::

## Esercizio: validare un campione

::: {.orange-box}
**Attivit√† (45 minuti)**

1. **Preparazione (10 min):** campione di **50 commenti**, foglio separato senza classificazione IA, 2 codificatori indipendenti
2. **Codifica (20 min):** classificare i 50 commenti con il codebook, annotare i casi difficili
3. **Confronto (15 min):** confrontare con classificazioni IA, costruire matrice di confusione, calcolare il kappa
:::

::: {.notes}
Esercizio pratico principale della sessione. Fase 1: la preparazione deve essere rapida; i dati sono gi√† nel foglio di calcolo dal lab di ieri. Creare un foglio separato con solo ID e testo del commento, senza la colonna della classificazione IA. Fase 2: la codifica individuale deve essere davvero indipendente ‚Äî i codificatori non devono comunicare durante questa fase. Fase 3: il confronto √® il momento pi√π interessante ‚Äî dove emergono i disaccordi e si capisce dove il codebook √® ambiguo. Passare tra i gruppi durante la Fase 3 per aiutare con il calcolo del kappa e l'interpretazione dei risultati.
:::

## Interpretare i risultati

::: {.columns}
::: {.column width="50%"}
### Se il kappa √® alto (> 0.60)

- La pipeline funziona bene
- L'IA √® un codificatore affidabile per queste categorie
- Si pu√≤ procedere con la classificazione del dataset completo
- Documentare nel paper
:::

::: {.column width="50%"}
### Se il kappa √® basso (< 0.60)

- Analizzare la **matrice di confusione**: dove sbaglia l'IA?
- Rivedere il **codebook**: le categorie sono ambigue?
- Raffinare il **prompt**: servono pi√π esempi?
- **Iterare:** ripetere la classificazione e la validazione
:::
:::

::: {.notes}
Guida all'interpretazione. Un kappa alto non significa che l'analisi √® finita ‚Äî significa che possiamo fidarci della classificazione IA per il dataset completo. Un kappa basso non √® un fallimento ‚Äî √® un'opportunit√† di miglioramento. Le fonti di disaccordo pi√π comuni: (1) categorie del codebook sovrapposte, (2) esempi insufficienti nel prompt, (3) commenti ambigui che richiedono contesto culturale. L'iterazione √® il cuore della metodologia: si raffina il prompt, si riclassifica, si ricalcola il kappa, fino a raggiungere un livello accettabile.
:::

## Iterazione e Raffinamento {background-color="#C5612E"}

::: {.notes}
Sezione 6: come migliorare la pipeline basandosi sui risultati della validazione.
:::

## Raffinamento e documentazione per il paper

::: {.columns}
::: {.column width="50%"}
### Ciclo di raffinamento

- Analizzare la **matrice di confusione**: dove sbaglia l'IA?
- Aggiungere **anti-esempi** al prompt (errori corretti)
- **Accorpare** categorie problematiche se necessario
- Ricalcolare il **kappa** dopo ogni iterazione
:::

::: {.column width="50%"}
### Cosa riportare nel paper

- **Codebook** con definizioni e esempi
- **Prompt finale** completo (in appendice)
- **Metriche**: kappa/alpha per categoria
- **Iterazioni**: cicli e miglioramenti
- **Modello IA**: versione e data
:::
:::

::: {.callout-note}
## Da ricordare
La **trasparenza metodologica** √® un valore fondamentale: documentate non solo i successi ma anche gli errori e le iterazioni. Questo rende la ricerca riproducibile e credibile.
:::

::: {.notes}
Due aspetti complementari: il raffinamento iterativo e la documentazione. Il ciclo prevede: analizzare errori, migliorare prompt e codebook, riclassificare, ricalcolare kappa. Gli anti-esempi nel prompt sono particolarmente efficaci: si aggiungono commenti che l'IA ha classificato erroneamente con la categoria corretta. Se dopo 2-3 iterazioni il kappa resta basso per alcune categorie, ripensare le categorie stesse. Per il paper, ogni elemento della pipeline deve essere riportato: prompt completo in appendice, metriche aggregate e per categoria, numero di iterazioni. Questo approccio segue i principi della scienza aperta e le raccomandazioni di Marino & Giglietto (2024).
:::

## Prossimi passi del progetto

| Data | Attivit√† |
|------|----------|
| **Mer 25 Marzo** | Consultazione gruppi ‚Äî revisione metodologica |
| **Lun 30 Marzo** | Workshop di scrittura ‚Äî struttura del paper |
| **Mar 31 Marzo** | Lavoro di gruppo ‚Äî stesura collaborativa |
| **Mer 1 Aprile** | Sintesi del corso ‚Äî consultazioni finali |
| **2 sett. prima appello** | **Consegna paper finale** |

::: {.highlight-box}
**Per domani:** preparate una breve **presentazione** (5 minuti) dei risultati della validazione per la consultazione di gruppo. Includete: kappa ottenuto, problemi emersi, strategie di miglioramento.
:::

::: {.notes}
Timeline aggiornata del progetto. Domani √® la consultazione di gruppo: ogni gruppo presenta i risultati della validazione e discute i problemi metodologici. La settimana 6 √® dedicata alla scrittura. Il paper va consegnato 2 settimane prima dell'appello di giugno. Enfatizzare che la validazione non deve essere perfetta per domani ‚Äî l'importante √® aver iniziato il processo e identificato i punti critici. La consultazione servira' per risolvere i problemi e pianificare la scrittura.
:::

## Grazie! {background-color="#C5612E"}

**Prossima lezione:** Consultazione Gruppi e Revisione (25 Marzo 2026)

üìß fabio.giglietto@uniurb.it

üåê blended.uniurb.it

::: {.notes}
Chiusura. Ricordare: (1) completare la validazione se non terminata in aula, (2) preparare la presentazione per la consultazione di domani (5 minuti, informale), (3) portare i risultati del kappa e la matrice di confusione. Domani ogni gruppo avr√† un momento dedicato di consultazione con il docente per discutere problemi specifici.
:::

## Riferimenti
